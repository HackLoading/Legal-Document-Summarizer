{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "J_dxH8Ifxhlr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_dxH8Ifxhlr",
        "outputId": "288d01b5-eb98-4190-ab06-c706793af7a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39bb7377",
      "metadata": {
        "id": "39bb7377"
      },
      "source": [
        "# ðŸš€ ArgLegalSumm Streamlit Web App on Google Colab\n",
        "\n",
        "Run the legal judgment summarizer Streamlit app directly in Google Colab and expose it on a public URL.\n",
        "\n",
        "Highlights:\n",
        "- No local setup required; runs entirely on Colab.\n",
        "- Two tunnel options for a public URL:\n",
        "  - Option A: pyngrok (token optional; recommended for stability)\n",
        "  - Option B: cloudflared (no token needed)\n",
        "- Load your model by uploading a .zip inside the app, or mount Google Drive and paste the path.\n",
        "\n",
        "Follow the notebook top-to-bottom. Only customize the configuration cell as needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "9ca3024c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ca3024c",
        "outputId": "3eb7c285-d9d9-4f4d-8798-91b62cfbcc1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python: 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n",
            "CUDA available: False\n"
          ]
        }
      ],
      "source": [
        "# Environment check\n",
        "import sys, subprocess, json, os, time, pathlib, shutil\n",
        "from pathlib import Path\n",
        "import torch\n",
        "print('Python:', sys.version)\n",
        "print('CUDA available:', torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "2e425671",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2e425671",
        "outputId": "2cc07f6c-3f23-4e57-94ca-5a401bbc4b23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OK: streamlit\n",
            "OK: transformers\n",
            "OK: peft\n",
            "OK: accelerate\n",
            "OK: pypdf\n",
            "OK: sentencepiece\n",
            "OK: pyngrok\n",
            "WARN: cloudflared import failed: cannot import name 'CloudFlare' from 'cloudflared.cloudflare' (/usr/local/lib/python3.12/dist-packages/cloudflared/cloudflare.py)\n",
            "\n",
            "Could not automatically find cloudflared executable in PATH.\n",
            "Could not find cloudflared executable in common pip install locations.\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies (ngrok optional; cloudflared optional)\n",
        "# Safe to run multiple times\n",
        "# Note: Colab images are reset on runtime restart\n",
        "!pip -q install streamlit \"transformers>=4.38.0\" peft accelerate pypdf sentencepiece\n",
        "!pip -q install pyngrok cloudflared\n",
        "import importlib, sys\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "for pkg in [\"streamlit\",\"transformers\",\"peft\",\"accelerate\",\"pypdf\",\"sentencepiece\",\"pyngrok\",\"cloudflared\"]:\n",
        "    try:\n",
        "        importlib.import_module(pkg)\n",
        "        print(f\"OK: {pkg}\")\n",
        "    except Exception as e:\n",
        "        print(f\"WARN: {pkg} import failed: {e}\")\n",
        "\n",
        "# Try to find cloudflared executable path after installation\n",
        "cloudflared_path = shutil.which(\"cloudflared\")\n",
        "if cloudflared_path:\n",
        "    print(f\"\\nFound cloudflared executable at: {cloudflared_path}\")\n",
        "else:\n",
        "    print(\"\\nCould not automatically find cloudflared executable in PATH.\")\n",
        "    # Attempt to find it in common pip install locations\n",
        "    for path in sys.path:\n",
        "        possible_path = Path(path) / \"..\" / \"bin\" / \"cloudflared\"\n",
        "        if possible_path.exists():\n",
        "            print(f\"Found possible cloudflared path in sys.path: {possible_path.resolve()}\")\n",
        "            break\n",
        "    else:\n",
        "        print(\"Could not find cloudflared executable in common pip install locations.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "b7ffa2ff",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7ffa2ff",
        "outputId": "0359cdd0-ebec-475a-ce5c-4287c48bcb8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'APP_PORT': 8501, 'USE_NGROK': False, 'BASE_MODEL': 'allenai/led-base-16384'}\n"
          ]
        }
      ],
      "source": [
        "# Configuration (edit as needed)\n",
        "APP_PORT = 8501\n",
        "USE_NGROK = False  # Set False to use cloudflared\n",
        "NGROK_AUTH_TOKEN = \"\"  # optional but helpful for stability\n",
        "BASE_MODEL = \"allenai/led-base-16384\"  # used by app when loading LoRA adapters\n",
        "import os\n",
        "os.environ[\"BASE_MODEL\"] = BASE_MODEL\n",
        "print({\"APP_PORT\": APP_PORT, \"USE_NGROK\": USE_NGROK, \"BASE_MODEL\": BASE_MODEL})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "a7b2f053",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7b2f053",
        "outputId": "6c06e045-95b2-4a31-ea5a-d4a42ea7327d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found: /content/drive/MyDrive/legal summarizer/output/dir/webapp/app_streamlit.py\n"
          ]
        }
      ],
      "source": [
        "# Hardcoded path for the webapp folder (replace with your actual path)\n",
        "# Example: /content/arglegalsumm-master/webapp (if you cloned the repo to /content)\n",
        "hardcoded_webapp_path = \"/content/drive/MyDrive/legal summarizer/output/dir/webapp\" # TODO: change to your path\n",
        "\n",
        "assert os.path.isdir(hardcoded_webapp_path), f'Missing: {hardcoded_webapp_path}'\n",
        "\n",
        "# Validate presence of app_streamlit.py\n",
        "app_py = Path(hardcoded_webapp_path) / 'app_streamlit.py'\n",
        "assert app_py.exists(), f'Expected app_streamlit.py at {app_py}. Ensure you specified the correct folder.'\n",
        "print('Found:', app_py)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "1a699703",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1a699703",
        "outputId": "4f92f5fb-8f7c-4ea5-d1a6-97319b7be235"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MODEL_DIR set to /content/drive/MyDrive/legal summarizer/output/dir/best\n",
            "BASE_MODEL: allenai/led-base-16384\n"
          ]
        }
      ],
      "source": [
        "# Optional: set DEFAULT_MODEL_DIR for the app; otherwise use Upload .zip in app sidebar\n",
        "import os\n",
        "DEFAULT_MODEL_DIR =  \"/content/drive/MyDrive/legal summarizer/output/dir/best\"\n",
        "if DEFAULT_MODEL_DIR:\n",
        "    os.environ[\"MODEL_DIR\"] = DEFAULT_MODEL_DIR\n",
        "    print('MODEL_DIR set to', DEFAULT_MODEL_DIR)\n",
        "else:\n",
        "    print('MODEL_DIR not set; use Upload .zip in the app sidebar.')\n",
        "\n",
        "# Ensure BASE_MODEL is exported (used for LoRA adapters)\n",
        "os.environ[\"BASE_MODEL\"] = os.environ.get(\"BASE_MODEL\", BASE_MODEL)\n",
        "print('BASE_MODEL:', os.environ[\"BASE_MODEL\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7bd91bb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7bd91bb",
        "outputId": "97301e7c-0879-4070-f326-4d5da889af30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting Streamlit with: cd /content/webapp && streamlit run app_streamlit.py --server.headless true --server.port 8501\n",
            "Streamlit process started (background).\n"
          ]
        }
      ],
      "source": [
        "# Start Streamlit app in background\n",
        "import subprocess, time\n",
        "cmd = f\"cd /content/webapp && streamlit run app_streamlit.py --server.headless true --server.port {APP_PORT}\"\n",
        "print('Starting Streamlit with:', cmd)\n",
        "sp = subprocess.Popen([\"bash\",\"-lc\", cmd], stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "time.sleep(3)\n",
        "print('Streamlit process started (background).')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "d8c9fe25",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8c9fe25",
        "outputId": "7fd67b74-f05a-4f4e-96af-26187e1cb6d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping ngrok; see 7B for cloudflared.\n"
          ]
        }
      ],
      "source": [
        "# 7A: Expose via pyngrok (if USE_NGROK)\n",
        "from pyngrok import ngrok\n",
        "public_url = None\n",
        "if USE_NGROK:\n",
        "    if NGROK_AUTH_TOKEN:\n",
        "        ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "    tunnel = ngrok.connect(APP_PORT, \"http\")\n",
        "    public_url = tunnel.public_url\n",
        "    print('Public URL (ngrok):', public_url)\n",
        "else:\n",
        "    print('Skipping ngrok; see 7B for cloudflared.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "1e0a82b4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "1e0a82b4",
        "outputId": "02bb05c1-fa9d-44f2-fc00-28d5ad822d44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading cloudflared to /content/cloudflared\n",
            "Starting cloudflared tunnel...\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3808100641.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msp_tunnel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# 7B (robust): Install and expose via cloudflared (no token)\n",
        "import os, re, sys, subprocess, time, shutil, stat, urllib.request\n",
        "\n",
        "def ensure_cloudflared():\n",
        "    path = shutil.which(\"cloudflared\")\n",
        "    if path:\n",
        "        print(\"cloudflared in PATH:\", path)\n",
        "        return path\n",
        "    # Download static binary to /content/cloudflared\n",
        "    url = \"https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64\"\n",
        "    dst = \"/content/cloudflared\"\n",
        "    print(\"Downloading cloudflared to\", dst)\n",
        "    urllib.request.urlretrieve(url, dst)\n",
        "    os.chmod(dst, os.stat(dst).st_mode | stat.S_IXUSR | stat.S_IXGRP | stat.S_IXOTH)\n",
        "    return dst\n",
        "\n",
        "cf_bin = ensure_cloudflared()\n",
        "print(\"Starting cloudflared tunnel...\")\n",
        "sp_tunnel = subprocess.Popen([\"bash\",\"-lc\", f\"{cf_bin} tunnel --url http://localhost:{APP_PORT} --no-autoupdate\"],\n",
        "                             stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "\n",
        "# Parse output for trycloudflare URL\n",
        "url = None\n",
        "for _ in range(400):\n",
        "    line = sp_tunnel.stdout.readline()\n",
        "    if not line:\n",
        "        time.sleep(0.1)\n",
        "        continue\n",
        "    if \"trycloudflare.com\" in line:\n",
        "        m = re.search(r\"https://[\\\\w.-]+trycloudflare.com\", line)\n",
        "        if m:\n",
        "            url = m.group(0)\n",
        "            print(\"Public URL (cloudflared):\", url)\n",
        "            break\n",
        "if not url:\n",
        "    print(\"Could not detect cloudflared URL yet; check logs above.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49f93daf",
      "metadata": {
        "id": "49f93daf"
      },
      "source": [
        "# Troubleshooting\n",
        "- If the app doesnâ€™t open:\n",
        "  - Re-run the install cell and restart the runtime if needed.\n",
        "  - Check that /content/webapp/app_streamlit.py exists (Cell 4 validates this).\n",
        "  - For large models, prefer Drive path instead of Upload .zip.\n",
        "  - In the app sidebar, you can upload your model/adapter .zip and set the Base model for LoRA (e.g., google/pegasus-large).\n",
        "- To stop/restart:\n",
        "  - Interrupt runtime or re-run the Start Streamlit cell; it will spawn a new process on the same port.\n",
        "  - Change APP_PORT in the config cell if port conflicts.\n",
        "- If ngrok rate limits:\n",
        "  - Provide your NGROK_AUTH_TOKEN or switch USE_NGROK=False to use cloudflared."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
